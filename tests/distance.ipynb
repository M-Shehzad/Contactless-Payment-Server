{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distance algorithms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance \n",
    "import numpy as np\n",
    "\n",
    "# Euclidean distance\n",
    "a = [1, 2, 3]\n",
    "b = [4, 5, 6]\n",
    "dst = distance.euclidean(a, b)\n",
    "\n",
    "# Manhattan distance\n",
    "dst = distance.cityblock(a, b)\n",
    "\n",
    "# Mahalanobis distance\n",
    "dst = distance.mahalanobis(a, b, np.cov(a, b))\n",
    "\n",
    "# Cosine distance\n",
    "dst = distance.cosine(a, b)\n",
    "\n",
    "# Jaccard distance\n",
    "dst = distance.jaccard(a, b)\n",
    "\n",
    "# Hamming distance\n",
    "dst = distance.hamming(a, b)\n",
    "\n",
    "# Chebyshev distance\n",
    "dst = distance.chebyshev(a, b)\n",
    "\n",
    "# Minkowski distance\n",
    "dst = distance.minkowski(a, b, 3)\n",
    "\n",
    "# Bray-Curtis distance\n",
    "dst = distance.braycurtis(a, b)\n",
    "\n",
    "# Canberra distance\n",
    "dst = distance.canberra(a, b)\n",
    "\n",
    "# Correlation distance\n",
    "dst = distance.correlation(a, b)\n",
    "\n",
    "# Chi-square distance\n",
    "dst = distance.chisquare(a, b)\n",
    "\n",
    "# Kullback-Leibler divergence\n",
    "dst = distance.kl_div(a, b)\n",
    "\n",
    "# Hellinger distance\n",
    "dst = distance.hellinger(a, b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>filename</th>\n",
       "      <th>integer_val</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>001_1.JPG</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142294</td>\n",
       "      <td>0.621808</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.403973</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.348059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.215420</td>\n",
       "      <td>0.694472</td>\n",
       "      <td>0.506776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>001_2.JPG</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.295348</td>\n",
       "      <td>0.437817</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.568328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.200792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.053549</td>\n",
       "      <td>0.900929</td>\n",
       "      <td>0.581803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>001_3.JPG</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.161544</td>\n",
       "      <td>0.641669</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.699172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.427063</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.247219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.793291</td>\n",
       "      <td>0.979200</td>\n",
       "      <td>0.420612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>001_4.JPG</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117513</td>\n",
       "      <td>0.719932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.344868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.101086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.451392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.376669</td>\n",
       "      <td>0.518925</td>\n",
       "      <td>0.568513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>001_5.JPG</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.171219</td>\n",
       "      <td>0.519987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.708153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.377871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.297778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.749215</td>\n",
       "      <td>0.993625</td>\n",
       "      <td>0.481102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   filename  integer_val    0    1         2         3    4         5   \n",
       "0      0  001_1.JPG            1  0.0  0.0  0.142294  0.621808  0.0  0.403973  \\\n",
       "1      1  001_2.JPG            1  0.0  0.0  0.295348  0.437817  0.0  0.568328   \n",
       "2      2  001_3.JPG            1  0.0  0.0  0.161544  0.641669  0.0  0.699172   \n",
       "3      3  001_4.JPG            1  0.0  0.0  0.117513  0.719932  0.0  0.344868   \n",
       "4      4  001_5.JPG            1  0.0  0.0  0.171219  0.519987  0.0  0.708153   \n",
       "\n",
       "     6  ...        22   23   24   25   26        27   28        29        30   \n",
       "0  0.0  ...  0.978720  0.0  0.0  0.0  0.0  1.348059  0.0  1.215420  0.694472  \\\n",
       "1  0.0  ...  0.725527  0.0  0.0  0.0  0.0  1.200792  0.0  1.053549  0.900929   \n",
       "2  0.0  ...  0.427063  0.0  0.0  0.0  0.0  1.247219  0.0  0.793291  0.979200   \n",
       "3  0.0  ...  1.101086  0.0  0.0  0.0  0.0  1.451392  0.0  1.376669  0.518925   \n",
       "4  0.0  ...  0.377871  0.0  0.0  0.0  0.0  1.297778  0.0  0.749215  0.993625   \n",
       "\n",
       "         31  \n",
       "0  0.506776  \n",
       "1  0.581803  \n",
       "2  0.420612  \n",
       "3  0.568513  \n",
       "4  0.481102  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('right.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '4', '17', '19', '20', '21', '25', '26', '28']\n"
     ]
    }
   ],
   "source": [
    "cols_to_remove = [col for col in df.columns if (df[col] == 0.0).all()]\n",
    "print(cols_to_remove)\n",
    "df = df.drop(cols_to_remove, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['integer_val', 'filename', 'index'], axis=1)\n",
    "y = df['integer_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;poly&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;poly&#x27;, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='poly', random_state=42)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "svm = SVC(kernel='poly', C=1.0, random_state=42)\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.00      0.00      0.00         1\n",
      "           5       1.00      0.33      0.50         3\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       1.00      1.00      1.00         2\n",
      "          10       0.33      1.00      0.50         1\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.50      0.50      0.50         2\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       1.00      0.50      0.67         2\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         1\n",
      "          19       1.00      0.50      0.67         2\n",
      "          20       0.00      0.00      0.00         0\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         0\n",
      "          23       1.00      1.00      1.00         1\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       1.00      1.00      1.00         1\n",
      "          27       0.00      0.00      0.00         1\n",
      "          28       0.00      0.00      0.00         0\n",
      "          29       1.00      1.00      1.00         1\n",
      "          30       1.00      0.67      0.80         3\n",
      "          31       1.00      1.00      1.00         1\n",
      "          33       0.00      0.00      0.00         0\n",
      "          34       0.00      0.00      0.00         1\n",
      "          35       0.00      0.00      0.00         0\n",
      "          37       0.00      0.00      0.00         0\n",
      "          38       0.00      0.00      0.00         0\n",
      "          39       0.50      1.00      0.67         1\n",
      "          40       0.00      0.00      0.00         2\n",
      "          41       0.00      0.00      0.00         0\n",
      "          42       0.00      0.00      0.00         0\n",
      "          43       0.00      0.00      0.00         0\n",
      "          44       1.00      1.00      1.00         1\n",
      "          45       1.00      0.50      0.67         2\n",
      "          46       0.50      0.50      0.50         2\n",
      "          47       0.00      0.00      0.00         0\n",
      "          48       1.00      1.00      1.00         2\n",
      "          49       0.00      0.00      0.00         4\n",
      "          50       0.50      1.00      0.67         1\n",
      "          51       0.00      0.00      0.00         1\n",
      "          52       0.00      0.00      0.00         1\n",
      "          53       0.50      0.33      0.40         3\n",
      "          54       0.00      0.00      0.00         0\n",
      "          55       1.00      0.50      0.67         2\n",
      "          57       0.00      0.00      0.00         3\n",
      "          58       0.00      0.00      0.00         0\n",
      "          59       0.00      0.00      0.00         1\n",
      "          60       0.00      0.00      0.00         4\n",
      "          61       1.00      1.00      1.00         3\n",
      "          62       0.00      0.00      0.00         1\n",
      "          63       0.00      0.00      0.00         0\n",
      "          64       1.00      1.00      1.00         1\n",
      "          65       0.50      0.50      0.50         2\n",
      "          66       0.00      0.00      0.00         1\n",
      "          67       0.00      0.00      0.00         2\n",
      "          68       0.00      0.00      0.00         2\n",
      "          69       0.00      0.00      0.00         0\n",
      "          70       0.00      0.00      0.00         0\n",
      "          71       0.00      0.00      0.00         0\n",
      "          72       0.00      0.00      0.00         1\n",
      "          74       0.50      1.00      0.67         1\n",
      "          75       0.00      0.00      0.00         0\n",
      "          77       1.00      0.33      0.50         3\n",
      "          78       1.00      0.50      0.67         2\n",
      "          79       0.00      0.00      0.00         0\n",
      "          80       0.00      0.00      0.00         0\n",
      "          81       1.00      0.25      0.40         4\n",
      "          82       0.00      0.00      0.00         0\n",
      "          83       0.00      0.00      0.00         0\n",
      "          84       0.00      0.00      0.00         0\n",
      "          85       0.00      0.00      0.00         1\n",
      "          86       0.00      0.00      0.00         1\n",
      "          87       0.00      0.00      0.00         0\n",
      "          88       0.50      1.00      0.67         1\n",
      "          89       0.00      0.00      0.00         0\n",
      "          90       0.00      0.00      0.00         1\n",
      "          91       0.00      0.00      0.00         5\n",
      "          92       0.00      0.00      0.00         1\n",
      "          94       0.00      0.00      0.00         0\n",
      "          95       1.00      0.50      0.67         2\n",
      "          96       0.00      0.00      0.00         0\n",
      "          97       0.00      0.00      0.00         2\n",
      "          98       1.00      1.00      1.00         1\n",
      "          99       0.00      0.00      0.00         0\n",
      "         100       0.00      0.00      0.00         1\n",
      "         101       0.00      0.00      0.00         0\n",
      "         103       1.00      1.00      1.00         1\n",
      "         104       0.00      0.00      0.00         2\n",
      "         105       0.00      0.00      0.00         0\n",
      "         106       0.00      0.00      0.00         0\n",
      "         107       0.00      0.00      0.00         1\n",
      "         108       0.50      1.00      0.67         1\n",
      "         109       1.00      1.00      1.00         1\n",
      "         110       1.00      1.00      1.00         1\n",
      "         111       1.00      0.50      0.67         2\n",
      "         112       0.33      1.00      0.50         1\n",
      "         113       0.00      0.00      0.00         0\n",
      "         114       0.50      0.50      0.50         2\n",
      "         115       0.00      0.00      0.00         1\n",
      "         116       0.00      0.00      0.00         0\n",
      "         117       0.00      0.00      0.00         2\n",
      "         118       0.00      0.00      0.00         1\n",
      "         119       0.00      0.00      0.00         0\n",
      "         120       1.00      1.00      1.00         2\n",
      "         121       1.00      1.00      1.00         3\n",
      "         122       0.67      0.67      0.67         3\n",
      "         123       0.00      0.00      0.00         1\n",
      "         126       1.00      0.67      0.80         3\n",
      "         127       0.00      0.00      0.00         1\n",
      "         128       0.50      1.00      0.67         1\n",
      "         129       0.50      1.00      0.67         1\n",
      "         130       0.00      0.00      0.00         1\n",
      "         131       0.00      0.00      0.00         1\n",
      "         132       1.00      1.00      1.00         1\n",
      "         133       0.00      0.00      0.00         1\n",
      "         134       0.00      0.00      0.00         2\n",
      "         135       0.00      0.00      0.00         2\n",
      "         136       0.00      0.00      0.00         1\n",
      "         137       1.00      1.00      1.00         1\n",
      "         139       1.00      0.17      0.29         6\n",
      "         140       1.00      0.50      0.67         2\n",
      "         141       0.50      0.50      0.50         2\n",
      "         142       0.00      0.00      0.00         1\n",
      "         144       0.00      0.00      0.00         0\n",
      "         145       0.00      0.00      0.00         1\n",
      "         146       0.50      1.00      0.67         1\n",
      "         147       0.00      0.00      0.00         2\n",
      "         148       1.00      0.50      0.67         2\n",
      "         149       1.00      1.00      1.00         1\n",
      "         150       0.00      0.00      0.00         0\n",
      "         151       0.00      0.00      0.00         0\n",
      "         152       0.00      0.00      0.00         0\n",
      "         153       0.33      1.00      0.50         1\n",
      "         154       0.00      0.00      0.00         2\n",
      "         155       0.00      0.00      0.00         0\n",
      "         157       0.67      1.00      0.80         2\n",
      "         158       0.00      0.00      0.00         3\n",
      "         160       0.50      1.00      0.67         1\n",
      "         161       1.00      1.00      1.00         1\n",
      "         162       0.00      0.00      0.00         0\n",
      "         164       1.00      1.00      1.00         1\n",
      "         165       0.00      0.00      0.00         0\n",
      "         166       0.00      0.00      0.00         0\n",
      "         167       0.00      0.00      0.00         3\n",
      "         168       0.00      0.00      0.00         2\n",
      "         169       0.00      0.00      0.00         0\n",
      "         170       0.00      0.00      0.00         1\n",
      "         172       1.00      1.00      1.00         1\n",
      "         174       1.00      0.33      0.50         3\n",
      "         175       0.00      0.00      0.00         1\n",
      "         176       0.67      0.67      0.67         3\n",
      "         178       1.00      1.00      1.00         1\n",
      "         179       1.00      1.00      1.00         1\n",
      "         180       1.00      1.00      1.00         2\n",
      "         181       1.00      0.33      0.50         3\n",
      "         182       1.00      0.67      0.80         3\n",
      "         184       1.00      1.00      1.00         1\n",
      "         185       1.00      1.00      1.00         1\n",
      "         186       1.00      1.00      1.00         2\n",
      "         187       1.00      1.00      1.00         2\n",
      "         189       1.00      1.00      1.00         2\n",
      "         190       0.00      0.00      0.00         2\n",
      "         191       1.00      1.00      1.00         1\n",
      "         192       0.00      0.00      0.00         3\n",
      "         193       0.00      0.00      0.00         0\n",
      "         195       0.00      0.00      0.00         3\n",
      "         196       1.00      1.00      1.00         2\n",
      "         197       0.50      0.50      0.50         2\n",
      "         199       1.00      0.33      0.50         3\n",
      "         200       0.00      0.00      0.00         1\n",
      "         202       1.00      1.00      1.00         1\n",
      "         203       0.00      0.00      0.00         5\n",
      "         206       0.00      0.00      0.00         0\n",
      "         207       0.00      0.00      0.00         1\n",
      "         208       0.25      1.00      0.40         1\n",
      "         209       0.00      0.00      0.00         1\n",
      "         211       1.00      1.00      1.00         2\n",
      "         212       0.00      0.00      0.00         1\n",
      "         213       1.00      1.00      1.00         1\n",
      "         214       1.00      1.00      1.00         1\n",
      "         215       0.00      0.00      0.00         0\n",
      "         216       1.00      0.50      0.67         2\n",
      "         217       1.00      1.00      1.00         1\n",
      "         218       0.00      0.00      0.00         1\n",
      "         219       0.00      0.00      0.00         1\n",
      "         220       1.00      1.00      1.00         1\n",
      "         221       0.67      1.00      0.80         2\n",
      "         222       1.00      0.12      0.22         8\n",
      "         223       0.00      0.00      0.00         0\n",
      "         224       0.33      1.00      0.50         1\n",
      "         225       0.00      0.00      0.00         1\n",
      "         226       0.50      1.00      0.67         1\n",
      "         227       0.00      0.00      0.00         1\n",
      "         228       0.50      0.33      0.40         3\n",
      "         229       0.50      0.33      0.40         3\n",
      "         230       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.41       260\n",
      "   macro avg       0.36      0.34      0.33       260\n",
      "weighted avg       0.52      0.41      0.42       260\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\User\\anaconda3\\envs\\palm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Users\\User\\anaconda3\\envs\\palm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Users\\User\\anaconda3\\envs\\palm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Users\\User\\anaconda3\\envs\\palm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Users\\User\\anaconda3\\envs\\palm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Users\\User\\anaconda3\\envs\\palm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(classification_report(predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.00      0.00      0.00         1\n",
      "           5       1.00      1.00      1.00         1\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.50      1.00      0.67         1\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       1.00      1.00      1.00         2\n",
      "          10       1.00      1.00      1.00         3\n",
      "          11       0.33      1.00      0.50         1\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       1.00      0.50      0.67         2\n",
      "          15       0.50      0.50      0.50         2\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         2\n",
      "          18       0.00      0.00      0.00         1\n",
      "          19       1.00      1.00      1.00         1\n",
      "          20       0.50      1.00      0.67         1\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         0\n",
      "          23       1.00      1.00      1.00         1\n",
      "          24       0.00      0.00      0.00         1\n",
      "          25       1.00      0.50      0.67         2\n",
      "          26       0.00      0.00      0.00         1\n",
      "          28       0.00      0.00      0.00         0\n",
      "          29       1.00      1.00      1.00         1\n",
      "          30       1.00      0.67      0.80         3\n",
      "          31       1.00      0.50      0.67         2\n",
      "          32       0.00      0.00      0.00         2\n",
      "          33       0.00      0.00      0.00         1\n",
      "          34       0.00      0.00      0.00         1\n",
      "          35       0.00      0.00      0.00         1\n",
      "          36       0.00      0.00      0.00         1\n",
      "          37       0.33      1.00      0.50         1\n",
      "          38       0.00      0.00      0.00         0\n",
      "          39       1.00      0.67      0.80         3\n",
      "          40       0.00      0.00      0.00         1\n",
      "          41       0.00      0.00      0.00         2\n",
      "          42       0.00      0.00      0.00         2\n",
      "          43       0.00      0.00      0.00         0\n",
      "          44       1.00      0.50      0.67         2\n",
      "          45       1.00      1.00      1.00         1\n",
      "          46       1.00      1.00      1.00         2\n",
      "          47       0.00      0.00      0.00         0\n",
      "          48       1.00      0.67      0.80         3\n",
      "          49       0.00      0.00      0.00         1\n",
      "          50       0.50      1.00      0.67         1\n",
      "          51       1.00      0.33      0.50         3\n",
      "          52       0.00      0.00      0.00         0\n",
      "          53       0.00      0.00      0.00         1\n",
      "          54       0.00      0.00      0.00         0\n",
      "          55       1.00      0.33      0.50         3\n",
      "          58       0.00      0.00      0.00         0\n",
      "          59       0.00      0.00      0.00         1\n",
      "          61       1.00      1.00      1.00         3\n",
      "          62       0.00      0.00      0.00         1\n",
      "          63       0.00      0.00      0.00         0\n",
      "          64       1.00      1.00      1.00         1\n",
      "          65       0.00      0.00      0.00         3\n",
      "          66       0.00      0.00      0.00         0\n",
      "          67       0.00      0.00      0.00         1\n",
      "          68       0.00      0.00      0.00         1\n",
      "          69       0.00      0.00      0.00         0\n",
      "          70       1.00      0.33      0.50         3\n",
      "          71       0.00      0.00      0.00         0\n",
      "          72       0.00      0.00      0.00         0\n",
      "          73       0.00      0.00      0.00         1\n",
      "          74       0.50      0.50      0.50         2\n",
      "          75       0.00      0.00      0.00         0\n",
      "          76       0.00      0.00      0.00         2\n",
      "          77       0.00      0.00      0.00         0\n",
      "          78       1.00      0.50      0.67         2\n",
      "          79       0.00      0.00      0.00         0\n",
      "          80       0.00      0.00      0.00         1\n",
      "          81       1.00      1.00      1.00         1\n",
      "          82       0.50      0.50      0.50         2\n",
      "          83       0.00      0.00      0.00         0\n",
      "          84       0.00      0.00      0.00         0\n",
      "          85       0.00      0.00      0.00         2\n",
      "          86       0.00      0.00      0.00         4\n",
      "          87       0.00      0.00      0.00         0\n",
      "          88       1.00      0.67      0.80         3\n",
      "          89       0.00      0.00      0.00         0\n",
      "          90       0.00      0.00      0.00         0\n",
      "          91       0.00      0.00      0.00         2\n",
      "          92       0.00      0.00      0.00         1\n",
      "          93       0.00      0.00      0.00         2\n",
      "          94       0.50      1.00      0.67         1\n",
      "          95       1.00      1.00      1.00         1\n",
      "          96       0.00      0.00      0.00         0\n",
      "          97       1.00      1.00      1.00         1\n",
      "          98       1.00      1.00      1.00         1\n",
      "          99       0.00      0.00      0.00         0\n",
      "         100       0.00      0.00      0.00         2\n",
      "         101       0.00      0.00      0.00         0\n",
      "         103       1.00      0.50      0.67         2\n",
      "         105       0.00      0.00      0.00         0\n",
      "         106       0.00      0.00      0.00         0\n",
      "         107       1.00      1.00      1.00         1\n",
      "         108       0.50      1.00      0.67         1\n",
      "         109       1.00      1.00      1.00         1\n",
      "         110       0.00      0.00      0.00         0\n",
      "         111       0.00      0.00      0.00         0\n",
      "         112       0.33      1.00      0.50         1\n",
      "         113       0.00      0.00      0.00         0\n",
      "         114       0.00      0.00      0.00         0\n",
      "         115       0.00      0.00      0.00         2\n",
      "         116       0.50      1.00      0.67         1\n",
      "         117       0.00      0.00      0.00         2\n",
      "         118       0.00      0.00      0.00         0\n",
      "         119       0.00      0.00      0.00         0\n",
      "         120       1.00      1.00      1.00         2\n",
      "         121       0.67      1.00      0.80         2\n",
      "         122       0.67      1.00      0.80         2\n",
      "         125       0.00      0.00      0.00         1\n",
      "         126       0.50      0.33      0.40         3\n",
      "         127       0.00      0.00      0.00         1\n",
      "         128       0.50      1.00      0.67         1\n",
      "         129       1.00      1.00      1.00         2\n",
      "         130       1.00      1.00      1.00         2\n",
      "         132       1.00      0.33      0.50         3\n",
      "         133       0.00      0.00      0.00         1\n",
      "         134       0.00      0.00      0.00         2\n",
      "         135       0.00      0.00      0.00         2\n",
      "         136       0.00      0.00      0.00         1\n",
      "         137       1.00      1.00      1.00         1\n",
      "         138       0.00      0.00      0.00         1\n",
      "         139       1.00      0.33      0.50         3\n",
      "         140       1.00      1.00      1.00         1\n",
      "         141       0.50      1.00      0.67         1\n",
      "         144       0.50      1.00      0.67         1\n",
      "         145       0.00      0.00      0.00         2\n",
      "         146       0.00      0.00      0.00         0\n",
      "         147       0.00      0.00      0.00         1\n",
      "         148       1.00      0.50      0.67         2\n",
      "         149       1.00      1.00      1.00         1\n",
      "         150       0.00      0.00      0.00         0\n",
      "         151       0.00      0.00      0.00         0\n",
      "         152       0.00      0.00      0.00         0\n",
      "         153       0.33      1.00      0.50         1\n",
      "         154       0.00      0.00      0.00         0\n",
      "         155       0.00      0.00      0.00         0\n",
      "         157       1.00      1.00      1.00         3\n",
      "         158       0.00      0.00      0.00         2\n",
      "         160       0.50      0.50      0.50         2\n",
      "         161       1.00      1.00      1.00         1\n",
      "         162       0.00      0.00      0.00         0\n",
      "         163       0.00      0.00      0.00         1\n",
      "         164       1.00      1.00      1.00         1\n",
      "         165       0.00      0.00      0.00         0\n",
      "         166       1.00      0.50      0.67         2\n",
      "         167       0.00      0.00      0.00         0\n",
      "         168       1.00      1.00      1.00         1\n",
      "         169       0.67      1.00      0.80         2\n",
      "         170       0.00      0.00      0.00         0\n",
      "         172       1.00      1.00      1.00         1\n",
      "         173       0.00      0.00      0.00         1\n",
      "         174       1.00      0.33      0.50         3\n",
      "         176       0.67      0.67      0.67         3\n",
      "         177       0.00      0.00      0.00         1\n",
      "         178       1.00      1.00      1.00         1\n",
      "         179       1.00      1.00      1.00         1\n",
      "         180       1.00      1.00      1.00         2\n",
      "         181       1.00      1.00      1.00         1\n",
      "         182       1.00      1.00      1.00         2\n",
      "         183       0.00      0.00      0.00         2\n",
      "         184       1.00      0.50      0.67         2\n",
      "         185       1.00      0.50      0.67         2\n",
      "         186       1.00      1.00      1.00         2\n",
      "         187       1.00      1.00      1.00         2\n",
      "         188       0.00      0.00      0.00         1\n",
      "         189       1.00      1.00      1.00         2\n",
      "         190       0.00      0.00      0.00         2\n",
      "         191       1.00      1.00      1.00         1\n",
      "         192       0.00      0.00      0.00         3\n",
      "         193       1.00      1.00      1.00         1\n",
      "         195       0.00      0.00      0.00         3\n",
      "         196       1.00      0.67      0.80         3\n",
      "         197       1.00      0.50      0.67         4\n",
      "         198       0.00      0.00      0.00         2\n",
      "         199       1.00      1.00      1.00         1\n",
      "         200       0.00      0.00      0.00         1\n",
      "         202       1.00      1.00      1.00         1\n",
      "         203       0.00      0.00      0.00         3\n",
      "         205       0.00      0.00      0.00         1\n",
      "         206       1.00      0.50      0.67         2\n",
      "         208       0.50      1.00      0.67         2\n",
      "         211       1.00      1.00      1.00         2\n",
      "         212       0.00      0.00      0.00         0\n",
      "         213       1.00      1.00      1.00         1\n",
      "         214       1.00      0.50      0.67         2\n",
      "         215       0.00      0.00      0.00         0\n",
      "         216       1.00      0.33      0.50         3\n",
      "         217       1.00      0.50      0.67         2\n",
      "         218       0.00      0.00      0.00         1\n",
      "         219       0.00      0.00      0.00         0\n",
      "         220       1.00      1.00      1.00         1\n",
      "         221       0.67      1.00      0.80         2\n",
      "         222       1.00      1.00      1.00         1\n",
      "         223       0.00      0.00      0.00         0\n",
      "         224       0.33      1.00      0.50         1\n",
      "         225       0.00      0.00      0.00         1\n",
      "         226       0.50      0.50      0.50         2\n",
      "         228       0.50      0.33      0.40         3\n",
      "         229       1.00      0.50      0.67         4\n",
      "\n",
      "    accuracy                           0.49       260\n",
      "   macro avg       0.41      0.39      0.37       260\n",
      "weighted avg       0.59      0.49      0.50       260\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\User\\anaconda3\\envs\\palm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Users\\User\\anaconda3\\envs\\palm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Users\\User\\anaconda3\\envs\\palm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Users\\User\\anaconda3\\envs\\palm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Users\\User\\anaconda3\\envs\\palm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Users\\User\\anaconda3\\envs\\palm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(weights=&#x27;distance&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(weights=&#x27;distance&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(weights='distance')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       1.00      0.50      0.67         2\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         2\n",
      "           9       1.00      1.00      1.00         2\n",
      "          10       0.67      0.67      0.67         3\n",
      "          11       0.33      1.00      0.50         1\n",
      "          12       0.00      0.00      0.00         1\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       1.00      0.50      0.67         2\n",
      "          15       0.00      0.00      0.00         0\n",
      "          16       0.00      0.00      0.00         0\n",
      "          19       1.00      0.50      0.67         2\n",
      "          20       0.50      1.00      0.67         1\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         1\n",
      "          23       0.00      0.00      0.00         0\n",
      "          25       1.00      0.50      0.67         2\n",
      "          28       0.00      0.00      0.00         0\n",
      "          29       1.00      0.50      0.67         2\n",
      "          30       1.00      0.67      0.80         3\n",
      "          31       0.00      0.00      0.00         0\n",
      "          32       0.00      0.00      0.00         1\n",
      "          33       0.00      0.00      0.00         1\n",
      "          34       0.00      0.00      0.00         1\n",
      "          35       0.00      0.00      0.00         0\n",
      "          37       0.33      0.50      0.40         2\n",
      "          38       0.00      0.00      0.00         0\n",
      "          39       1.00      1.00      1.00         2\n",
      "          40       0.00      0.00      0.00         1\n",
      "          41       0.00      0.00      0.00         0\n",
      "          42       0.00      0.00      0.00         2\n",
      "          43       0.00      0.00      0.00         0\n",
      "          44       1.00      0.50      0.67         2\n",
      "          45       1.00      1.00      1.00         1\n",
      "          46       1.00      1.00      1.00         2\n",
      "          47       0.00      0.00      0.00         0\n",
      "          48       1.00      0.67      0.80         3\n",
      "          49       0.00      0.00      0.00         1\n",
      "          50       0.50      1.00      0.67         1\n",
      "          51       0.00      0.00      0.00         0\n",
      "          52       1.00      0.67      0.80         3\n",
      "          53       0.50      1.00      0.67         1\n",
      "          54       0.00      0.00      0.00         3\n",
      "          55       1.00      1.00      1.00         1\n",
      "          57       0.00      0.00      0.00         2\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.00      0.00      0.00         1\n",
      "          61       1.00      1.00      1.00         3\n",
      "          62       0.00      0.00      0.00         0\n",
      "          63       0.50      1.00      0.67         1\n",
      "          64       1.00      1.00      1.00         1\n",
      "          65       0.50      1.00      0.67         1\n",
      "          66       0.00      0.00      0.00         0\n",
      "          68       0.00      0.00      0.00         2\n",
      "          69       0.00      0.00      0.00         0\n",
      "          70       1.00      1.00      1.00         1\n",
      "          71       0.00      0.00      0.00         0\n",
      "          72       0.50      0.50      0.50         2\n",
      "          74       0.50      0.25      0.33         4\n",
      "          75       0.00      0.00      0.00         0\n",
      "          77       1.00      0.50      0.67         2\n",
      "          78       1.00      0.50      0.67         2\n",
      "          79       0.00      0.00      0.00         1\n",
      "          80       0.00      0.00      0.00         0\n",
      "          81       1.00      0.25      0.40         4\n",
      "          82       1.00      0.50      0.67         4\n",
      "          83       0.00      0.00      0.00         0\n",
      "          84       0.00      0.00      0.00         0\n",
      "          85       0.00      0.00      0.00         1\n",
      "          86       0.00      0.00      0.00         3\n",
      "          87       0.00      0.00      0.00         0\n",
      "          88       1.00      0.67      0.80         3\n",
      "          89       0.00      0.00      0.00         1\n",
      "          90       0.00      0.00      0.00         1\n",
      "          91       0.00      0.00      0.00         2\n",
      "          92       0.00      0.00      0.00         1\n",
      "          93       0.00      0.00      0.00         1\n",
      "          94       0.00      0.00      0.00         0\n",
      "          95       1.00      0.33      0.50         3\n",
      "          96       0.00      0.00      0.00         1\n",
      "          97       0.00      0.00      0.00         0\n",
      "          98       1.00      1.00      1.00         1\n",
      "          99       0.00      0.00      0.00         0\n",
      "         100       0.00      0.00      0.00         1\n",
      "         101       0.00      0.00      0.00         0\n",
      "         103       1.00      1.00      1.00         1\n",
      "         105       0.00      0.00      0.00         0\n",
      "         106       0.00      0.00      0.00         1\n",
      "         107       0.00      0.00      0.00         1\n",
      "         108       0.50      1.00      0.67         1\n",
      "         109       1.00      1.00      1.00         1\n",
      "         110       0.00      0.00      0.00         0\n",
      "         111       0.00      0.00      0.00         1\n",
      "         112       0.33      1.00      0.50         1\n",
      "         113       0.00      0.00      0.00         0\n",
      "         114       0.00      0.00      0.00         1\n",
      "         115       0.00      0.00      0.00         1\n",
      "         116       0.50      1.00      0.67         1\n",
      "         117       0.00      0.00      0.00         2\n",
      "         118       1.00      1.00      1.00         1\n",
      "         119       0.00      0.00      0.00         0\n",
      "         120       1.00      1.00      1.00         2\n",
      "         121       0.67      1.00      0.80         2\n",
      "         122       0.67      1.00      0.80         2\n",
      "         124       0.00      0.00      0.00         1\n",
      "         126       0.50      0.50      0.50         2\n",
      "         128       0.50      1.00      0.67         1\n",
      "         129       1.00      1.00      1.00         2\n",
      "         130       1.00      1.00      1.00         2\n",
      "         132       1.00      0.33      0.50         3\n",
      "         133       0.00      0.00      0.00         2\n",
      "         134       0.00      0.00      0.00         2\n",
      "         135       0.00      0.00      0.00         2\n",
      "         136       0.00      0.00      0.00         1\n",
      "         137       1.00      1.00      1.00         1\n",
      "         138       0.00      0.00      0.00         1\n",
      "         139       1.00      0.50      0.67         2\n",
      "         140       1.00      1.00      1.00         1\n",
      "         141       1.00      0.67      0.80         3\n",
      "         144       0.50      1.00      0.67         1\n",
      "         145       0.00      0.00      0.00         1\n",
      "         146       0.00      0.00      0.00         0\n",
      "         147       0.00      0.00      0.00         1\n",
      "         148       1.00      1.00      1.00         1\n",
      "         149       1.00      1.00      1.00         1\n",
      "         150       0.00      0.00      0.00         0\n",
      "         151       0.00      0.00      0.00         0\n",
      "         152       0.00      0.00      0.00         0\n",
      "         153       0.33      1.00      0.50         1\n",
      "         154       0.00      0.00      0.00         1\n",
      "         155       0.00      0.00      0.00         0\n",
      "         157       1.00      1.00      1.00         3\n",
      "         158       0.00      0.00      0.00         2\n",
      "         160       0.50      1.00      0.67         1\n",
      "         161       1.00      1.00      1.00         1\n",
      "         162       1.00      1.00      1.00         1\n",
      "         164       1.00      0.50      0.67         2\n",
      "         165       0.00      0.00      0.00         0\n",
      "         166       1.00      1.00      1.00         1\n",
      "         167       0.00      0.00      0.00         1\n",
      "         168       1.00      1.00      1.00         1\n",
      "         169       0.33      1.00      0.50         1\n",
      "         170       0.00      0.00      0.00         0\n",
      "         172       1.00      1.00      1.00         1\n",
      "         174       1.00      0.50      0.67         2\n",
      "         175       0.00      0.00      0.00         1\n",
      "         176       1.00      0.60      0.75         5\n",
      "         177       0.00      0.00      0.00         1\n",
      "         178       1.00      1.00      1.00         1\n",
      "         179       1.00      1.00      1.00         1\n",
      "         180       1.00      1.00      1.00         2\n",
      "         181       1.00      0.50      0.67         2\n",
      "         182       1.00      1.00      1.00         2\n",
      "         184       1.00      0.50      0.67         2\n",
      "         185       1.00      1.00      1.00         1\n",
      "         186       1.00      1.00      1.00         2\n",
      "         187       1.00      1.00      1.00         2\n",
      "         189       1.00      1.00      1.00         2\n",
      "         190       0.00      0.00      0.00         3\n",
      "         191       1.00      0.33      0.50         3\n",
      "         192       0.00      0.00      0.00         2\n",
      "         193       1.00      1.00      1.00         1\n",
      "         195       0.00      0.00      0.00         2\n",
      "         196       1.00      0.67      0.80         3\n",
      "         197       1.00      0.67      0.80         3\n",
      "         198       0.00      0.00      0.00         2\n",
      "         199       1.00      1.00      1.00         1\n",
      "         200       0.00      0.00      0.00         1\n",
      "         202       1.00      1.00      1.00         1\n",
      "         203       0.00      0.00      0.00         1\n",
      "         205       0.00      0.00      0.00         1\n",
      "         206       1.00      0.25      0.40         4\n",
      "         208       0.50      1.00      0.67         2\n",
      "         211       1.00      1.00      1.00         2\n",
      "         212       0.00      0.00      0.00         1\n",
      "         213       1.00      1.00      1.00         1\n",
      "         214       1.00      0.50      0.67         2\n",
      "         215       0.00      0.00      0.00         0\n",
      "         216       1.00      0.50      0.67         2\n",
      "         217       1.00      1.00      1.00         1\n",
      "         218       0.00      0.00      0.00         1\n",
      "         219       0.00      0.00      0.00         2\n",
      "         220       1.00      1.00      1.00         1\n",
      "         221       0.67      1.00      0.80         2\n",
      "         222       1.00      1.00      1.00         1\n",
      "         223       0.00      0.00      0.00         0\n",
      "         224       0.33      1.00      0.50         1\n",
      "         225       0.00      0.00      0.00         4\n",
      "         226       0.50      1.00      0.67         1\n",
      "         227       0.00      0.00      0.00         1\n",
      "         228       0.50      0.50      0.50         2\n",
      "         229       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.50       260\n",
      "   macro avg       0.43      0.41      0.40       260\n",
      "weighted avg       0.60      0.50      0.51       260\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\User\\anaconda3\\envs\\palm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Users\\User\\anaconda3\\envs\\palm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Users\\User\\anaconda3\\envs\\palm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Users\\User\\anaconda3\\envs\\palm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Users\\User\\anaconda3\\envs\\palm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Users\\User\\anaconda3\\envs\\palm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         9\n",
      "           5       1.00      0.50      0.67         2\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       0.33      1.00      0.50         1\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       1.00      1.00      1.00         1\n",
      "          15       0.00      0.00      0.00         4\n",
      "          16       0.00      0.00      0.00         0\n",
      "          19       1.00      1.00      1.00         1\n",
      "          20       0.00      0.00      0.00         2\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         0\n",
      "          23       0.00      0.00      0.00         0\n",
      "          25       0.00      0.00      0.00         0\n",
      "          26       0.00      0.00      0.00         6\n",
      "          28       0.00      0.00      0.00         1\n",
      "          29       0.00      0.00      0.00         3\n",
      "          30       1.00      1.00      1.00         2\n",
      "          31       1.00      1.00      1.00         1\n",
      "          32       0.00      0.00      0.00         2\n",
      "          33       0.00      0.00      0.00         0\n",
      "          34       0.00      0.00      0.00         0\n",
      "          35       0.00      0.00      0.00         0\n",
      "          37       0.33      0.50      0.40         2\n",
      "          38       0.00      0.00      0.00         0\n",
      "          39       0.50      1.00      0.67         1\n",
      "          40       1.00      1.00      1.00         1\n",
      "          41       0.00      0.00      0.00         0\n",
      "          42       0.00      0.00      0.00         0\n",
      "          43       0.00      0.00      0.00         1\n",
      "          44       1.00      1.00      1.00         1\n",
      "          45       1.00      1.00      1.00         1\n",
      "          46       0.50      1.00      0.67         1\n",
      "          47       1.00      0.04      0.08        24\n",
      "          48       1.00      1.00      1.00         2\n",
      "          49       0.00      0.00      0.00         0\n",
      "          50       0.50      0.50      0.50         2\n",
      "          51       1.00      1.00      1.00         1\n",
      "          52       0.50      1.00      0.67         1\n",
      "          53       0.00      0.00      0.00         1\n",
      "          54       0.00      0.00      0.00         2\n",
      "          55       0.00      0.00      0.00         0\n",
      "          57       0.00      0.00      0.00         1\n",
      "          58       0.00      0.00      0.00         6\n",
      "          59       0.00      0.00      0.00         2\n",
      "          61       0.33      1.00      0.50         1\n",
      "          62       0.00      0.00      0.00         3\n",
      "          63       0.00      0.00      0.00         0\n",
      "          64       1.00      0.50      0.67         2\n",
      "          65       0.50      1.00      0.67         1\n",
      "          66       0.00      0.00      0.00         1\n",
      "          67       0.00      0.00      0.00        13\n",
      "          69       0.00      0.00      0.00         4\n",
      "          70       0.00      0.00      0.00         0\n",
      "          71       0.00      0.00      0.00         0\n",
      "          72       0.00      0.00      0.00         0\n",
      "          74       0.50      1.00      0.67         1\n",
      "          75       0.50      0.33      0.40         3\n",
      "          76       0.00      0.00      0.00         1\n",
      "          77       0.00      0.00      0.00         0\n",
      "          78       1.00      1.00      1.00         1\n",
      "          79       0.00      0.00      0.00         0\n",
      "          80       0.00      0.00      0.00         1\n",
      "          81       0.00      0.00      0.00         1\n",
      "          82       0.50      0.50      0.50         2\n",
      "          83       0.00      0.00      0.00         1\n",
      "          84       0.00      0.00      0.00         4\n",
      "          85       0.00      0.00      0.00         0\n",
      "          86       0.00      0.00      0.00         1\n",
      "          87       0.00      0.00      0.00         0\n",
      "          88       0.50      1.00      0.67         1\n",
      "          89       0.00      0.00      0.00         1\n",
      "          90       0.00      0.00      0.00         0\n",
      "          91       0.00      0.00      0.00         5\n",
      "          93       0.00      0.00      0.00         1\n",
      "          94       0.00      0.00      0.00         0\n",
      "          95       0.00      0.00      0.00         0\n",
      "          96       0.00      0.00      0.00         0\n",
      "          97       0.00      0.00      0.00         0\n",
      "          98       0.00      0.00      0.00         0\n",
      "          99       0.00      0.00      0.00         0\n",
      "         100       0.00      0.00      0.00         2\n",
      "         101       0.00      0.00      0.00         4\n",
      "         103       0.00      0.00      0.00         1\n",
      "         105       0.00      0.00      0.00         0\n",
      "         106       0.00      0.00      0.00         0\n",
      "         107       0.00      0.00      0.00         0\n",
      "         108       0.50      0.50      0.50         2\n",
      "         109       1.00      0.50      0.67         2\n",
      "         110       0.00      0.00      0.00         1\n",
      "         111       1.00      0.33      0.50         3\n",
      "         112       0.33      0.50      0.40         2\n",
      "         113       0.00      0.00      0.00         0\n",
      "         114       0.00      0.00      0.00         0\n",
      "         116       0.50      0.09      0.15        11\n",
      "         117       0.00      0.00      0.00         1\n",
      "         118       0.00      0.00      0.00         0\n",
      "         119       0.00      0.00      0.00         0\n",
      "         120       0.50      1.00      0.67         1\n",
      "         121       0.00      0.00      0.00         0\n",
      "         122       0.00      0.00      0.00         0\n",
      "         125       0.00      0.00      0.00         3\n",
      "         126       0.50      0.50      0.50         2\n",
      "         128       0.00      0.00      0.00         0\n",
      "         129       0.00      0.00      0.00         0\n",
      "         130       0.50      1.00      0.67         1\n",
      "         131       0.00      0.00      0.00         9\n",
      "         132       1.00      0.50      0.67         2\n",
      "         133       0.00      0.00      0.00         0\n",
      "         134       0.00      0.00      0.00         8\n",
      "         136       0.00      0.00      0.00         1\n",
      "         137       1.00      0.50      0.67         2\n",
      "         139       0.00      0.00      0.00         1\n",
      "         140       1.00      1.00      1.00         1\n",
      "         141       0.00      0.00      0.00         1\n",
      "         144       0.00      0.00      0.00         2\n",
      "         146       0.00      0.00      0.00         0\n",
      "         147       0.00      0.00      0.00         2\n",
      "         148       0.00      0.00      0.00         0\n",
      "         149       1.00      1.00      1.00         1\n",
      "         150       0.00      0.00      0.00         0\n",
      "         151       0.00      0.00      0.00         0\n",
      "         152       0.00      0.00      0.00         0\n",
      "         153       0.33      1.00      0.50         1\n",
      "         154       0.00      0.00      0.00         0\n",
      "         155       0.00      0.00      0.00         0\n",
      "         157       0.67      1.00      0.80         2\n",
      "         160       0.50      1.00      0.67         1\n",
      "         161       1.00      0.50      0.67         2\n",
      "         162       1.00      1.00      1.00         1\n",
      "         164       0.00      0.00      0.00         0\n",
      "         165       0.00      0.00      0.00         0\n",
      "         166       0.00      0.00      0.00         0\n",
      "         167       1.00      1.00      1.00         1\n",
      "         168       0.00      0.00      0.00         2\n",
      "         169       0.00      0.00      0.00         0\n",
      "         170       0.00      0.00      0.00         0\n",
      "         172       1.00      1.00      1.00         1\n",
      "         174       1.00      1.00      1.00         1\n",
      "         176       0.33      1.00      0.50         1\n",
      "         178       1.00      1.00      1.00         1\n",
      "         179       1.00      1.00      1.00         1\n",
      "         180       1.00      1.00      1.00         2\n",
      "         181       1.00      1.00      1.00         1\n",
      "         182       0.50      1.00      0.67         1\n",
      "         184       0.00      0.00      0.00         0\n",
      "         185       1.00      1.00      1.00         1\n",
      "         186       1.00      1.00      1.00         2\n",
      "         187       1.00      1.00      1.00         2\n",
      "         189       1.00      1.00      1.00         2\n",
      "         191       1.00      1.00      1.00         1\n",
      "         193       0.00      0.00      0.00         0\n",
      "         195       0.00      0.00      0.00         0\n",
      "         196       0.50      1.00      0.67         1\n",
      "         197       0.50      1.00      0.67         1\n",
      "         199       1.00      1.00      1.00         1\n",
      "         202       0.00      0.00      0.00         0\n",
      "         205       0.00      0.00      0.00         1\n",
      "         206       0.00      0.00      0.00         0\n",
      "         208       0.00      0.00      0.00         0\n",
      "         211       0.50      0.50      0.50         2\n",
      "         212       0.00      0.00      0.00         2\n",
      "         213       1.00      1.00      1.00         1\n",
      "         214       1.00      1.00      1.00         1\n",
      "         215       0.00      0.00      0.00         0\n",
      "         216       1.00      0.50      0.67         2\n",
      "         217       1.00      1.00      1.00         1\n",
      "         219       0.00      0.00      0.00         0\n",
      "         220       1.00      1.00      1.00         1\n",
      "         221       0.67      1.00      0.80         2\n",
      "         222       0.00      0.00      0.00         1\n",
      "         223       0.00      0.00      0.00         2\n",
      "         224       0.00      0.00      0.00         0\n",
      "         226       0.50      1.00      0.67         1\n",
      "         228       1.00      0.33      0.50         6\n",
      "         229       0.00      0.00      0.00         0\n",
      "         230       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.30       260\n",
      "   macro avg       0.29      0.31      0.28       260\n",
      "weighted avg       0.41      0.30      0.29       260\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\User\\anaconda3\\envs\\palm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Users\\User\\anaconda3\\envs\\palm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Users\\User\\anaconda3\\envs\\palm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Users\\User\\anaconda3\\envs\\palm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Users\\User\\anaconda3\\envs\\palm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Users\\User\\anaconda3\\envs\\palm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "predictions = gnb.predict(X_test)\n",
    "\n",
    "print(classification_report(predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         3\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         4\n",
      "           9       0.50      1.00      0.67         1\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       0.00      0.00      0.00         0\n",
      "          15       0.00      0.00      0.00         0\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         2\n",
      "          19       1.00      0.50      0.67         2\n",
      "          20       0.00      0.00      0.00         0\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         0\n",
      "          23       0.00      0.00      0.00         0\n",
      "          24       0.00      0.00      0.00         1\n",
      "          25       0.00      0.00      0.00         1\n",
      "          26       0.00      0.00      0.00         2\n",
      "          28       0.00      0.00      0.00         0\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.00      0.00      0.00         0\n",
      "          31       1.00      1.00      1.00         1\n",
      "          32       0.00      0.00      0.00         1\n",
      "          33       0.00      0.00      0.00         0\n",
      "          34       0.00      0.00      0.00         0\n",
      "          35       0.00      0.00      0.00         0\n",
      "          36       0.00      0.00      0.00         3\n",
      "          37       0.00      0.00      0.00         0\n",
      "          38       0.00      0.00      0.00         0\n",
      "          39       0.00      0.00      0.00         0\n",
      "          40       0.00      0.00      0.00         0\n",
      "          41       0.00      0.00      0.00         0\n",
      "          42       0.00      0.00      0.00         0\n",
      "          43       0.00      0.00      0.00         0\n",
      "          44       0.00      0.00      0.00         0\n",
      "          45       1.00      1.00      1.00         1\n",
      "          46       0.00      0.00      0.00         0\n",
      "          47       0.00      0.00      0.00         0\n",
      "          48       0.00      0.00      0.00         0\n",
      "          49       0.00      0.00      0.00         0\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.00      0.00      0.00         3\n",
      "          52       0.00      0.00      0.00         0\n",
      "          53       0.00      0.00      0.00         0\n",
      "          54       0.00      0.00      0.00         0\n",
      "          55       0.00      0.00      0.00         0\n",
      "          56       0.00      0.00      0.00         5\n",
      "          57       0.00      0.00      0.00         3\n",
      "          58       0.00      0.00      0.00         0\n",
      "          59       0.00      0.00      0.00        10\n",
      "          60       0.00      0.00      0.00        10\n",
      "          61       0.00      0.00      0.00         0\n",
      "          62       0.00      0.00      0.00         0\n",
      "          63       0.00      0.00      0.00         0\n",
      "          64       0.00      0.00      0.00         1\n",
      "          65       0.00      0.00      0.00         0\n",
      "          66       0.00      0.00      0.00         0\n",
      "          67       0.00      0.00      0.00         6\n",
      "          68       0.00      0.00      0.00         1\n",
      "          69       0.00      0.00      0.00         0\n",
      "          70       0.00      0.00      0.00         0\n",
      "          71       0.00      0.00      0.00         0\n",
      "          72       0.00      0.00      0.00         0\n",
      "          74       0.00      0.00      0.00         0\n",
      "          75       0.00      0.00      0.00         0\n",
      "          77       0.00      0.00      0.00         0\n",
      "          78       1.00      0.50      0.67         2\n",
      "          79       0.00      0.00      0.00         0\n",
      "          80       0.00      0.00      0.00         0\n",
      "          81       0.00      0.00      0.00         0\n",
      "          82       0.00      0.00      0.00         0\n",
      "          83       0.00      0.00      0.00         0\n",
      "          84       0.00      0.00      0.00         0\n",
      "          85       0.00      0.00      0.00         0\n",
      "          87       0.00      0.00      0.00         0\n",
      "          88       0.00      0.00      0.00         0\n",
      "          89       0.00      0.00      0.00         0\n",
      "          90       0.00      0.00      0.00         0\n",
      "          91       0.00      0.00      0.00        13\n",
      "          94       0.00      0.00      0.00         0\n",
      "          95       0.00      0.00      0.00         0\n",
      "          96       0.00      0.00      0.00         0\n",
      "          97       0.00      0.00      0.00         0\n",
      "          98       0.00      0.00      0.00         0\n",
      "          99       0.00      0.00      0.00         0\n",
      "         100       0.00      0.00      0.00         0\n",
      "         101       0.00      0.00      0.00         0\n",
      "         103       0.00      0.00      0.00         0\n",
      "         104       0.00      0.00      0.00         8\n",
      "         105       0.00      0.00      0.00         0\n",
      "         106       0.00      0.00      0.00         0\n",
      "         107       0.00      0.00      0.00         0\n",
      "         108       0.00      0.00      0.00         0\n",
      "         109       0.00      0.00      0.00         0\n",
      "         110       0.00      0.00      0.00         0\n",
      "         111       0.00      0.00      0.00         1\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.00      0.00      0.00         0\n",
      "         114       0.00      0.00      0.00         0\n",
      "         115       0.00      0.00      0.00         5\n",
      "         116       0.00      0.00      0.00         0\n",
      "         117       0.00      0.00      0.00         0\n",
      "         118       0.00      0.00      0.00         0\n",
      "         119       0.00      0.00      0.00         0\n",
      "         120       0.00      0.00      0.00         0\n",
      "         121       0.00      0.00      0.00         0\n",
      "         122       0.00      0.00      0.00         0\n",
      "         125       0.00      0.00      0.00        11\n",
      "         126       0.00      0.00      0.00         0\n",
      "         128       0.00      0.00      0.00         0\n",
      "         129       0.00      0.00      0.00         0\n",
      "         130       0.00      0.00      0.00         0\n",
      "         131       0.00      0.00      0.00         1\n",
      "         132       0.00      0.00      0.00         0\n",
      "         133       0.00      0.00      0.00         0\n",
      "         134       0.00      0.00      0.00         3\n",
      "         135       0.00      0.00      0.00         1\n",
      "         136       0.00      0.00      0.00         4\n",
      "         137       0.00      0.00      0.00         0\n",
      "         138       0.00      0.00      0.00         2\n",
      "         139       0.00      0.00      0.00         0\n",
      "         140       1.00      0.20      0.33         5\n",
      "         141       0.00      0.00      0.00         0\n",
      "         142       0.00      0.00      0.00         1\n",
      "         144       0.00      0.00      0.00         0\n",
      "         145       0.00      0.00      0.00         3\n",
      "         146       0.00      0.00      0.00         0\n",
      "         148       0.00      0.00      0.00         0\n",
      "         149       0.00      0.00      0.00         0\n",
      "         150       0.00      0.00      0.00         0\n",
      "         151       0.00      0.00      0.00         0\n",
      "         152       0.00      0.00      0.00         0\n",
      "         153       0.00      0.00      0.00         0\n",
      "         154       0.00      0.00      0.00         1\n",
      "         155       0.00      0.00      0.00         0\n",
      "         157       0.00      0.00      0.00         0\n",
      "         158       0.00      0.00      0.00         7\n",
      "         160       0.50      1.00      0.67         1\n",
      "         161       0.00      0.00      0.00         0\n",
      "         162       0.00      0.00      0.00         0\n",
      "         163       0.00      0.00      0.00         2\n",
      "         164       0.00      0.00      0.00         0\n",
      "         165       0.00      0.00      0.00         0\n",
      "         166       0.00      0.00      0.00         0\n",
      "         167       0.00      0.00      0.00         0\n",
      "         168       0.00      0.00      0.00         0\n",
      "         169       0.00      0.00      0.00         0\n",
      "         170       0.00      0.00      0.00         0\n",
      "         172       0.00      0.00      0.00         1\n",
      "         174       0.00      0.00      0.00         0\n",
      "         176       0.00      0.00      0.00         0\n",
      "         177       0.00      0.00      0.00        10\n",
      "         178       1.00      1.00      1.00         1\n",
      "         179       1.00      1.00      1.00         1\n",
      "         180       0.00      0.00      0.00         0\n",
      "         181       1.00      0.50      0.67         2\n",
      "         182       0.00      0.00      0.00         0\n",
      "         183       0.00      0.00      0.00         8\n",
      "         184       0.00      0.00      0.00         0\n",
      "         185       1.00      0.33      0.50         3\n",
      "         186       1.00      1.00      1.00         2\n",
      "         187       1.00      1.00      1.00         2\n",
      "         188       0.00      0.00      0.00         1\n",
      "         189       0.00      0.00      0.00         0\n",
      "         190       0.00      0.00      0.00        12\n",
      "         191       0.00      0.00      0.00         5\n",
      "         193       1.00      0.25      0.40         4\n",
      "         194       0.00      0.00      0.00         1\n",
      "         195       0.00      0.00      0.00         4\n",
      "         196       0.00      0.00      0.00         0\n",
      "         197       0.00      0.00      0.00         0\n",
      "         198       0.00      0.00      0.00         1\n",
      "         199       0.00      0.00      0.00         0\n",
      "         200       0.00      0.00      0.00         4\n",
      "         201       0.00      0.00      0.00         2\n",
      "         202       1.00      0.50      0.67         2\n",
      "         203       0.00      0.00      0.00        11\n",
      "         204       0.00      0.00      0.00         1\n",
      "         205       0.00      0.00      0.00         7\n",
      "         206       0.00      0.00      0.00         1\n",
      "         208       0.00      0.00      0.00         0\n",
      "         209       0.00      0.00      0.00        17\n",
      "         210       0.00      0.00      0.00         4\n",
      "         211       0.00      0.00      0.00         0\n",
      "         212       0.00      0.00      0.00         3\n",
      "         213       1.00      1.00      1.00         1\n",
      "         214       1.00      1.00      1.00         1\n",
      "         215       0.00      0.00      0.00         0\n",
      "         216       1.00      0.33      0.50         3\n",
      "         217       1.00      0.50      0.67         2\n",
      "         218       0.00      0.00      0.00         4\n",
      "         219       0.00      0.00      0.00         0\n",
      "         220       1.00      0.50      0.67         2\n",
      "         221       0.00      0.00      0.00         0\n",
      "         222       0.00      0.00      0.00         0\n",
      "         223       0.00      0.00      0.00         0\n",
      "         224       0.00      0.00      0.00         0\n",
      "         225       0.00      0.00      0.00         3\n",
      "         226       0.50      1.00      0.67         1\n",
      "         227       0.00      0.00      0.00         1\n",
      "         228       0.00      0.00      0.00         0\n",
      "         229       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.09       260\n",
      "   macro avg       0.09      0.07      0.08       260\n",
      "weighted avg       0.15      0.09      0.10       260\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\User\\anaconda3\\envs\\palm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Users\\User\\anaconda3\\envs\\palm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Users\\User\\anaconda3\\envs\\palm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Users\\User\\anaconda3\\envs\\palm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Users\\User\\anaconda3\\envs\\palm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Users\\User\\anaconda3\\envs\\palm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train)\n",
    "predictions = mnb.predict(X_test)\n",
    "print(classification_report(predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       0.00      0.00      0.00         0\n",
      "          15       0.00      0.00      0.00         0\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00        25\n",
      "          18       0.00      0.00      0.00        50\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       0.00      0.00      0.00         0\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         0\n",
      "          23       0.00      0.00      0.00         0\n",
      "          25       0.00      0.00      0.00         0\n",
      "          26       0.00      0.00      0.00         1\n",
      "          28       0.00      0.00      0.00         0\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.00      0.00      0.00         0\n",
      "          31       0.00      0.00      0.00         0\n",
      "          33       0.00      0.00      0.00         0\n",
      "          34       0.00      0.00      0.00         0\n",
      "          35       0.00      0.00      0.00         0\n",
      "          37       0.00      0.00      0.00         0\n",
      "          38       0.00      0.00      0.00         0\n",
      "          39       0.00      0.00      0.00         0\n",
      "          40       0.00      0.00      0.00         2\n",
      "          41       0.00      0.00      0.00         0\n",
      "          42       0.00      0.00      0.00         0\n",
      "          43       0.00      0.00      0.00         0\n",
      "          44       0.00      0.00      0.00         0\n",
      "          45       1.00      1.00      1.00         1\n",
      "          46       0.00      0.00      0.00         0\n",
      "          47       0.00      0.00      0.00         0\n",
      "          48       0.00      0.00      0.00         0\n",
      "          49       0.00      0.00      0.00         0\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.00      0.00      0.00         2\n",
      "          52       0.00      0.00      0.00         0\n",
      "          53       0.00      0.00      0.00         0\n",
      "          54       0.00      0.00      0.00         0\n",
      "          55       0.00      0.00      0.00         0\n",
      "          58       0.00      0.00      0.00         0\n",
      "          61       0.00      0.00      0.00         0\n",
      "          62       0.00      0.00      0.00         0\n",
      "          63       0.00      0.00      0.00         0\n",
      "          64       0.00      0.00      0.00         0\n",
      "          65       0.00      0.00      0.00         0\n",
      "          66       0.00      0.00      0.00         0\n",
      "          69       0.00      0.00      0.00         0\n",
      "          70       0.00      0.00      0.00         0\n",
      "          71       0.00      0.00      0.00         0\n",
      "          72       0.00      0.00      0.00         0\n",
      "          74       0.00      0.00      0.00         0\n",
      "          75       0.00      0.00      0.00         0\n",
      "          77       0.00      0.00      0.00         0\n",
      "          78       0.00      0.00      0.00         0\n",
      "          79       0.00      0.00      0.00         0\n",
      "          80       0.00      0.00      0.00         0\n",
      "          81       0.00      0.00      0.00         0\n",
      "          82       0.00      0.00      0.00         0\n",
      "          83       0.00      0.00      0.00         0\n",
      "          84       0.00      0.00      0.00         0\n",
      "          85       0.00      0.00      0.00         0\n",
      "          87       0.00      0.00      0.00         0\n",
      "          88       0.00      0.00      0.00         0\n",
      "          89       0.00      0.00      0.00         0\n",
      "          90       0.00      0.00      0.00         0\n",
      "          94       0.00      0.00      0.00         0\n",
      "          95       0.00      0.00      0.00         0\n",
      "          96       0.00      0.00      0.00         0\n",
      "          97       0.00      0.00      0.00         0\n",
      "          98       0.00      0.00      0.00         0\n",
      "          99       0.00      0.00      0.00         0\n",
      "         100       0.00      0.00      0.00         0\n",
      "         101       0.00      0.00      0.00         0\n",
      "         103       0.00      0.00      0.00         0\n",
      "         105       0.00      0.00      0.00         0\n",
      "         106       0.00      0.00      0.00         0\n",
      "         107       0.00      0.00      0.00         0\n",
      "         108       0.00      0.00      0.00         0\n",
      "         109       0.00      0.00      0.00         0\n",
      "         110       0.00      0.00      0.00         0\n",
      "         111       0.00      0.00      0.00         0\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.00      0.00      0.00         0\n",
      "         114       0.00      0.00      0.00         0\n",
      "         116       0.00      0.00      0.00         0\n",
      "         117       0.00      0.00      0.00         0\n",
      "         118       0.00      0.00      0.00         0\n",
      "         119       0.00      0.00      0.00         0\n",
      "         120       0.00      0.00      0.00         0\n",
      "         121       0.00      0.00      0.00         0\n",
      "         122       0.00      0.00      0.00         0\n",
      "         125       0.00      0.00      0.00         3\n",
      "         126       0.00      0.00      0.00         0\n",
      "         127       0.00      0.00      0.00        12\n",
      "         128       0.00      0.00      0.00         0\n",
      "         129       0.00      0.00      0.00         0\n",
      "         130       0.00      0.00      0.00         0\n",
      "         132       0.00      0.00      0.00         0\n",
      "         133       0.00      0.00      0.00         0\n",
      "         136       0.00      0.00      0.00         3\n",
      "         137       0.00      0.00      0.00         0\n",
      "         138       0.00      0.00      0.00         2\n",
      "         139       0.00      0.00      0.00         0\n",
      "         140       1.00      0.20      0.33         5\n",
      "         141       0.00      0.00      0.00         0\n",
      "         144       0.00      0.00      0.00         0\n",
      "         145       0.00      0.00      0.00         1\n",
      "         146       0.00      0.00      0.00         0\n",
      "         148       0.00      0.00      0.00         0\n",
      "         149       0.00      0.00      0.00         0\n",
      "         150       0.00      0.00      0.00         0\n",
      "         151       0.00      0.00      0.00         0\n",
      "         152       0.00      0.00      0.00         0\n",
      "         153       0.00      0.00      0.00         0\n",
      "         154       0.00      0.00      0.00         3\n",
      "         155       0.00      0.00      0.00         0\n",
      "         156       0.00      0.00      0.00         1\n",
      "         157       0.00      0.00      0.00         0\n",
      "         158       0.00      0.00      0.00        90\n",
      "         160       0.00      0.00      0.00         0\n",
      "         161       0.00      0.00      0.00         0\n",
      "         162       0.00      0.00      0.00         0\n",
      "         164       0.00      0.00      0.00         0\n",
      "         165       0.00      0.00      0.00         0\n",
      "         166       0.00      0.00      0.00         0\n",
      "         167       0.00      0.00      0.00         0\n",
      "         168       0.00      0.00      0.00         0\n",
      "         169       0.00      0.00      0.00         0\n",
      "         170       0.00      0.00      0.00         0\n",
      "         172       0.00      0.00      0.00         0\n",
      "         174       0.00      0.00      0.00         0\n",
      "         176       0.00      0.00      0.00         0\n",
      "         178       1.00      0.50      0.67         2\n",
      "         179       0.00      0.00      0.00         0\n",
      "         180       0.00      0.00      0.00         0\n",
      "         181       0.00      0.00      0.00         0\n",
      "         182       0.00      0.00      0.00         1\n",
      "         184       0.00      0.00      0.00         1\n",
      "         185       0.00      0.00      0.00         3\n",
      "         186       0.00      0.00      0.00         0\n",
      "         187       1.00      1.00      1.00         2\n",
      "         189       0.00      0.00      0.00         0\n",
      "         190       0.00      0.00      0.00        17\n",
      "         191       0.00      0.00      0.00         0\n",
      "         193       0.00      0.00      0.00         0\n",
      "         195       0.00      0.00      0.00         0\n",
      "         196       0.00      0.00      0.00         0\n",
      "         197       0.00      0.00      0.00         0\n",
      "         199       0.00      0.00      0.00         0\n",
      "         200       0.00      0.00      0.00         2\n",
      "         201       0.00      0.00      0.00        10\n",
      "         202       0.00      0.00      0.00         0\n",
      "         206       0.00      0.00      0.00         1\n",
      "         207       0.00      0.00      0.00         7\n",
      "         208       0.00      0.00      0.00         0\n",
      "         209       0.00      0.00      0.00         6\n",
      "         210       0.00      0.00      0.00         4\n",
      "         211       0.00      0.00      0.00         0\n",
      "         212       0.00      0.00      0.00         0\n",
      "         213       0.00      0.00      0.00         0\n",
      "         214       0.00      0.00      0.00         0\n",
      "         215       0.00      0.00      0.00         0\n",
      "         216       1.00      0.50      0.67         2\n",
      "         217       1.00      1.00      1.00         1\n",
      "         219       0.00      0.00      0.00         0\n",
      "         220       0.00      0.00      0.00         0\n",
      "         221       0.00      0.00      0.00         0\n",
      "         222       0.00      0.00      0.00         0\n",
      "         223       0.00      0.00      0.00         0\n",
      "         224       0.00      0.00      0.00         0\n",
      "         226       0.00      0.00      0.00         0\n",
      "         228       0.00      0.00      0.00         0\n",
      "         229       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.03       260\n",
      "   macro avg       0.03      0.02      0.03       260\n",
      "weighted avg       0.05      0.03      0.03       260\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\User\\anaconda3\\envs\\palm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Users\\User\\anaconda3\\envs\\palm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Users\\User\\anaconda3\\envs\\palm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Users\\User\\anaconda3\\envs\\palm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Users\\User\\anaconda3\\envs\\palm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Users\\User\\anaconda3\\envs\\palm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, y_train)\n",
    "predictions = bnb.predict(X_test)\n",
    "print(classification_report(predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
